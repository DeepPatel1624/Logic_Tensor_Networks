{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef09cbdd",
   "metadata": {},
   "source": [
    "# Grounding in Logic Tensor Networks (LTN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1ecaac",
   "metadata": {},
   "source": [
    "LTN interprets symbols which are grounded on real-valued features, we use the term grounding G. G associates a tensor of real numbers to any term of the language, and a real number in the interval to any formula f.\n",
    "\n",
    "The language consists of a non-logical part (the signature) and logical connectives and quantifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "575e554d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ltn\n",
      "  Downloading ltn-2.1-py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting numpy (from ltn)\n",
      "  Downloading numpy-2.4.1-cp313-cp313-macosx_14_0_arm64.whl.metadata (6.6 kB)\n",
      "INFO: pip is looking at multiple versions of ltn to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting ltn\n",
      "  Downloading ltn-2.0.tar.gz (14 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tensorflow (from ltn)\n",
      "  Using cached tensorflow-2.20.0-cp313-cp313-macosx_12_0_arm64.whl.metadata (4.5 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow->ltn)\n",
      "  Downloading absl_py-2.4.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow->ltn)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow->ltn)\n",
      "  Downloading flatbuffers-25.12.19-py2.py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow->ltn)\n",
      "  Downloading gast-0.7.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting google_pasta>=0.1.1 (from tensorflow->ltn)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow->ltn)\n",
      "  Using cached libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting opt_einsum>=2.3.2 (from tensorflow->ltn)\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.13/site-packages (from tensorflow->ltn) (26.0)\n",
      "Collecting protobuf>=5.28.0 (from tensorflow->ltn)\n",
      "  Downloading protobuf-6.33.5-cp39-abi3-macosx_10_9_universal2.whl.metadata (593 bytes)\n",
      "Collecting requests<3,>=2.21.0 (from tensorflow->ltn)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting setuptools (from tensorflow->ltn)\n",
      "  Using cached setuptools-80.10.2-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in ./.venv/lib/python3.13/site-packages (from tensorflow->ltn) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow->ltn)\n",
      "  Downloading termcolor-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting typing_extensions>=3.6.6 (from tensorflow->ltn)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow->ltn)\n",
      "  Using cached wrapt-2.0.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (9.0 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow->ltn)\n",
      "  Using cached grpcio-1.76.0-cp313-cp313-macosx_11_0_universal2.whl.metadata (3.7 kB)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow->ltn)\n",
      "  Using cached tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.10.0 (from tensorflow->ltn)\n",
      "  Downloading keras-3.13.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting h5py>=3.11.0 (from tensorflow->ltn)\n",
      "  Using cached h5py-3.15.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (3.0 kB)\n",
      "Collecting ml_dtypes<1.0.0,>=0.5.1 (from tensorflow->ltn)\n",
      "  Downloading ml_dtypes-0.5.4-cp313-cp313-macosx_10_13_universal2.whl.metadata (8.9 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests<3,>=2.21.0->tensorflow->ltn)\n",
      "  Using cached charset_normalizer-3.4.4-cp313-cp313-macosx_10_13_universal2.whl.metadata (37 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2.21.0->tensorflow->ltn)\n",
      "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.21.0->tensorflow->ltn)\n",
      "  Downloading urllib3-2.6.3-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorflow->ltn)\n",
      "  Downloading certifi-2026.1.4-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.20.0->tensorflow->ltn)\n",
      "  Downloading markdown-3.10.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting pillow (from tensorboard~=2.20.0->tensorflow->ltn)\n",
      "  Downloading pillow-12.1.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (8.8 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.20.0->tensorflow->ltn)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard~=2.20.0->tensorflow->ltn)\n",
      "  Downloading werkzeug-3.1.5-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow->ltn)\n",
      "  Downloading wheel-0.46.3-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting rich (from keras>=3.10.0->tensorflow->ltn)\n",
      "  Downloading rich-14.3.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.10.0->tensorflow->ltn)\n",
      "  Using cached namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.10.0->tensorflow->ltn)\n",
      "  Using cached optree-0.18.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (34 kB)\n",
      "Collecting markupsafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow->ltn)\n",
      "  Using cached markupsafe-3.0.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (2.7 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.10.0->tensorflow->ltn)\n",
      "  Using cached markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.13/site-packages (from rich->keras>=3.10.0->tensorflow->ltn) (2.19.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow->ltn)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading numpy-2.4.1-cp313-cp313-macosx_14_0_arm64.whl (5.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m410.5 kB/s\u001b[0m  \u001b[33m0:00:12\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached tensorflow-2.20.0-cp313-cp313-macosx_12_0_arm64.whl (200.7 MB)\n",
      "Using cached grpcio-1.76.0-cp313-cp313-macosx_11_0_universal2.whl (11.8 MB)\n",
      "Downloading ml_dtypes-0.5.4-cp313-cp313-macosx_10_13_universal2.whl (676 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m676.9/676.9 kB\u001b[0m \u001b[31m322.3 kB/s\u001b[0m  \u001b[33m0:00:01\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.4-cp313-cp313-macosx_10_13_universal2.whl (208 kB)\n",
      "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
      "Using cached tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Downloading urllib3-2.6.3-py3-none-any.whl (131 kB)\n",
      "Downloading absl_py-2.4.0-py3-none-any.whl (135 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading wheel-0.46.3-py3-none-any.whl (30 kB)\n",
      "Downloading certifi-2026.1.4-py3-none-any.whl (152 kB)\n",
      "Downloading flatbuffers-25.12.19-py2.py3-none-any.whl (26 kB)\n",
      "Downloading gast-0.7.0-py3-none-any.whl (22 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Using cached h5py-3.15.1-cp313-cp313-macosx_11_0_arm64.whl (2.8 MB)\n",
      "Downloading keras-3.13.2-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m647.7 kB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl (25.8 MB)\n",
      "Downloading markdown-3.10.1-py3-none-any.whl (107 kB)\n",
      "Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading protobuf-6.33.5-cp39-abi3-macosx_10_9_universal2.whl (427 kB)\n",
      "Using cached setuptools-80.10.2-py3-none-any.whl (1.1 MB)\n",
      "Downloading termcolor-3.3.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading werkzeug-3.1.5-py3-none-any.whl (225 kB)\n",
      "Using cached markupsafe-3.0.3-cp313-cp313-macosx_11_0_arm64.whl (12 kB)\n",
      "Using cached wrapt-2.0.1-cp313-cp313-macosx_11_0_arm64.whl (61 kB)\n",
      "Using cached namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Using cached optree-0.18.0-cp313-cp313-macosx_11_0_arm64.whl (346 kB)\n",
      "Downloading pillow-12.1.0-cp313-cp313-macosx_11_0_arm64.whl (4.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m434.4 kB/s\u001b[0m  \u001b[33m0:00:10\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading rich-14.3.1-py3-none-any.whl (309 kB)\n",
      "Using cached markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Building wheels for collected packages: ltn\n",
      "  Building wheel for ltn (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ltn: filename=ltn-2.0-py3-none-any.whl size=8974 sha256=9b24842ebb6821ecdef49b132da7abe4d62ddc8089bcf4c3b13b31ac64b4e6d3\n",
      "  Stored in directory: /Users/deep/Library/Caches/pip/wheels/46/69/0d/220aa9aff805dbe98bedf75f09ed14cef2b68d46349b2ff6d2\n",
      "Successfully built ltn\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, wheel, urllib3, typing_extensions, termcolor, tensorboard-data-server, setuptools, protobuf, pillow, opt_einsum, numpy, mdurl, markupsafe, markdown, idna, google_pasta, gast, charset_normalizer, certifi, absl-py, werkzeug, requests, optree, ml_dtypes, markdown-it-py, h5py, grpcio, astunparse, tensorboard, rich, keras, tensorflow, ltn\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36/36\u001b[0m [ltn]32m34/36\u001b[0m [tensorflow]]\n",
      "\u001b[1A\u001b[2KSuccessfully installed absl-py-2.4.0 astunparse-1.6.3 certifi-2026.1.4 charset_normalizer-3.4.4 flatbuffers-25.12.19 gast-0.7.0 google_pasta-0.2.0 grpcio-1.76.0 h5py-3.15.1 idna-3.11 keras-3.13.2 libclang-18.1.1 ltn-2.0 markdown-3.10.1 markdown-it-py-4.0.0 markupsafe-3.0.3 mdurl-0.1.2 ml_dtypes-0.5.4 namex-0.1.0 numpy-2.4.1 opt_einsum-3.4.0 optree-0.18.0 pillow-12.1.0 protobuf-6.33.5 requests-2.32.5 rich-14.3.1 setuptools-80.10.2 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tensorflow-2.20.0 termcolor-3.3.0 typing_extensions-4.15.0 urllib3-2.6.3 werkzeug-3.1.5 wheel-0.46.3 wrapt-2.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ltn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a103af6",
   "metadata": {},
   "source": [
    "## Grounding in Logical Tensor Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ceba9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ltn\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a83978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "c1 = ltn.Constant([2.1, 3] , trainable=False)\n",
    "c2 = ltn.Constant([[4.2,3,2.5],[4,-1.3,1.8]], trainable=False)\n",
    "\n",
    "#Note that a constant can be set as learnable by using the keyword\n",
    "#argument trainable=True. This is useful to learn embeddings for\n",
    "#some individuals. The features of the tensor will be considered as\n",
    "#trainable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f41a3bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "c3 = ltn.Constant([0.,0.] ,trainable=True)\n",
    "#You can access the TensorFlow value of a LTN constant or any LTN expression x by querying x.tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64394986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ltn.Constant(tensor=[2.1 3. ], trainable=False, free_vars=[])\n",
      "tf.Tensor([2.1 3. ], shape=(2,), dtype=float32)\n",
      "ltn.Constant(tensor=[[ 4.2  3.   2.5]\n",
      " [ 4.  -1.3  1.8]], trainable=False, free_vars=[])\n",
      "tf.Tensor(\n",
      "[[ 4.2  3.   2.5]\n",
      " [ 4.  -1.3  1.8]], shape=(2, 3), dtype=float32)\n",
      "ltn.Constant(tensor=<tf.Variable 'Variable:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>, trainable=True, free_vars=[])\n",
      "<tf.Variable 'Variable:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "print(c1)\n",
    "print(c1.tensor)\n",
    "print(c2)\n",
    "print(c2.tensor)\n",
    "print(c3)\n",
    "print(c3.tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56350838",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicates\n",
    "\n",
    "mu = tf.constant([2.,3.])\n",
    "P1 = ltn.Predicate.Lambda(lambda x : tf.exp(-tf.norm(x-mu,axis=1)))\n",
    "\n",
    "class ModelP2(tf.keras.Model):\n",
    "    #\"https://www.tensorflow.org/api_docs/python/tf/keras/Model\"\n",
    "    def __init__(self):\n",
    "        super(ModelP2, self).__init__()\n",
    "        self.dense1 = tf.keras.layers.Dense(5, activation=tf.nn.elu)\n",
    "        self.dense2 = tf.keras.layers.Dense(1, activation=tf.nn.sigmoid) # returns one value in [0,1]\n",
    "    def call(self, x):\n",
    "        x = self.dense1(x)\n",
    "        return self.dense2(x)\n",
    "\n",
    "modelP2 = ModelP2()\n",
    "P2 = ltn.Predicate(modelP2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4648b56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ltn.Formula(tensor=0.9048374891281128, free_vars=[])\n"
     ]
    }
   ],
   "source": [
    "#One can easily query predicates using LTN constants and LTN variables\n",
    "c1 = ltn.Constant([2.1,3],trainable=False)\n",
    "c2 = ltn.Constant([4.5,0.8],trainable=False)\n",
    "\n",
    "print(P1(c1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62b7b8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ltn.Formula(tensor=0.9872696995735168, free_vars=[])\n"
     ]
    }
   ],
   "source": [
    "class ModelP3(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(ModelP3, self).__init__()\n",
    "        self.dense1 = tf.keras.layers.Dense(5, activation=tf.nn.elu)\n",
    "        self.dense2 = tf.keras.layers.Dense(1, activation=tf.nn.sigmoid) # returns one value in [0,1]\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x1, x2 = inputs[0], inputs[1] # multiple arguments are passed as a list\n",
    "        x = tf.concat([x1,x2],axis=1) # axis=0 is the batch axis\n",
    "        x = self.dense1(x)\n",
    "        return self.dense2(x)\n",
    "    \n",
    "P3 = ltn.Predicate(ModelP3())\n",
    "print(P3([c1,c2])) # multiple arguments are passed as a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2700037d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ltn.Proposition(tensor=0.30000001192092896, trainable=False, free_vars=[])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Declaring a trainable 0-ary predicate with initial truth value 0.3\n",
    "A = ltn.Proposition(0.3, trainable=False)\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7bfbe507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "\"\"\"\n",
    "the default constructor ltn.Function(model) takes in argument a tf.keras.Model instance; it can be used to ground any custom function (succession of operations, Deep Neural Network, ...),\n",
    "the lambda constructor ltn.Function.Lambda(function) takes in argument a lambda function; it is appropriate for small mathematical operations with no weight tracking (non-trainable function).\n",
    "\"\"\"\n",
    "\n",
    "f1 = ltn.Function.Lambda(lambda args: args[0]-args[1])\n",
    "\n",
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.dense1 = tf.keras.layers.Dense(4, activation=tf.nn.relu)\n",
    "        self.dense2 = tf.keras.layers.Dense(5)\n",
    "    def call(self, x):\n",
    "        x = self.dense1(x)\n",
    "        return self.dense2(x)\n",
    "\n",
    "model_f2  = MyModel()\n",
    "f2 = ltn.Function(model_f2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ca6a1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ltn.Term(tensor=[-2.4  2.2], free_vars=[])\n",
      "ltn.Term(tensor=[-1.1321932 -0.9576021  0.1673333 -1.9088415 -0.2597782], free_vars=[])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "c1 = ltn.Constant([2.1,3], trainable=False)\n",
    "c2 = ltn.Constant([4.5,0.8], trainable=False)\n",
    "print(f1([c1,c2])) # multiple arguments are passed as a list\n",
    "print(f2(c1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3bceaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ltn.Variable(label=x, tensor=[[-0.6622027   2.3706868 ]\n",
      " [-0.7119895   1.0917885 ]\n",
      " [ 1.7085938   0.868343  ]\n",
      " [-0.23839763  2.2870016 ]\n",
      " [-0.81183326 -1.2873626 ]\n",
      " [-1.0229675  -0.88876134]\n",
      " [ 1.0546168   1.5523195 ]\n",
      " [-0.6659683  -0.02354109]\n",
      " [ 0.1472501  -0.4015604 ]\n",
      " [-0.40952152 -1.0498368 ]], free_vars=['x'])\n"
     ]
    }
   ],
   "source": [
    "#variables\n",
    "\n",
    "\"\"\"\n",
    "TN variables are sequences of individuals/constants from a domain. Variables are useful to write quantified statements\n",
    "\"\"\"\n",
    "\n",
    "#The following defines two variables and x and y\n",
    "# with respectively 10 and 5 individuals, sampled from normal distributions \n",
    "\n",
    "x = ltn.Variable('x', np.random.normal(0.,1.,(10,2)))\n",
    "y = ltn.Variable('y',np.random.normal(0.,4.,(5,2)))\n",
    "\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea39d1b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ltn.Formula(tensor=[[0.9445251  0.99786943 0.6884894  0.34428936 0.38078645]\n",
      " [0.91775936 0.9968835  0.6011971  0.26200792 0.29250276]\n",
      " [0.90213776 0.99651223 0.5480611  0.17460628 0.19977736]\n",
      " [0.9432688  0.9978344  0.68200684 0.32575727 0.3619223 ]\n",
      " [0.7989366  0.992503   0.419      0.13307758 0.15446018]\n",
      " [0.83140767 0.99375004 0.46359465 0.15700844 0.181491  ]\n",
      " [0.92615503 0.9973126  0.6162216  0.23719613 0.26619172]\n",
      " [0.87712383 0.9954754  0.51440614 0.19392799 0.21958849]\n",
      " [0.8514917  0.99459153 0.45052028 0.15094696 0.1726312 ]\n",
      " [0.812923   0.99308664 0.41767448 0.13424884 0.1548102 ]], free_vars=['x', 'y'])\n",
      "ltn.Formula(tensor=0.9021377563476562, free_vars=[])\n"
     ]
    }
   ],
   "source": [
    "# Notice that the outcome is a 2 dimensional tensor where each cell\n",
    "# represents the satisfiability of P3 with each individual in x and in y.\n",
    "res1 = P3([x,y])\n",
    "print(res1) \n",
    "print(res1.take('x',2).take('y',0)) # gives the result calculated with the 3rd individual in x and the 1st individual in y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87d40b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 5, 2)\n",
      "['x', 'y']\n",
      "ltn.Term(tensor=[-1.2298062  0.752656 ], free_vars=[])\n"
     ]
    }
   ],
   "source": [
    "# This is also valid with the outputs of `ltn.Function`\n",
    "res2 = f1([x,y])\n",
    "print(res2.tensor.shape)\n",
    "print(res2.free_vars)\n",
    "print(res2.take('x',2).take('y',0)) # gives the result calculated with the 3rd individual in x and the 1st individual in y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f7b6f211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ltn.Formula(tensor=[0.9539946  0.99829996 0.72398144 0.30053917 0.3466746 ], free_vars=['y'])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "res3 = P3([c1,y])\n",
    "print(res3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28d41527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0023127, -0.0438941], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Variables made of trainable constants\n",
    "\n",
    "c1 = ltn.Constant([2.1,3], trainable=True)\n",
    "c2 = ltn.Constant([4.5,0.8], trainable=True)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    # the assignation must be done within a tf.GradientTape.\n",
    "    # Tensorflow will keep track of the gradients between c1/c2 and x.\n",
    "    x = ltn.Variable.from_constants(\"x\", [c1,c2], tape=tape)\n",
    "    res = P2(x)\n",
    "tape.gradient(res.tensor,c1.tensor).numpy() # the tape keeps track of gradients between P2(x), x and c1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee7b64f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef1f84b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a944ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22aea764",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
